{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e9edc0-a7e2-4e2d-a696-a78988edb6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7008a0fa-59e3-4207-9e98-d97a9e9d2f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d67e55-536e-41ef-8983-42820366a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['education'] = train['Have you Completed your Graduation ?'] + ' ' + train['Highest Educational Qualification']\n",
    "train = train.drop(['Have you Completed your Graduation ?', 'Highest Educational Qualification', 'Residential Pincode', 'Branch Pincode'], axis=1)\n",
    "test['education'] = test['Have you Completed your Graduation ?'] + ' ' + test['Highest Educational Qualification']\n",
    "test = test.drop(['Have you Completed your Graduation ?', 'Highest Educational Qualification', 'Residential Pincode', 'Branch Pincode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f367e103-5126-4ccf-9ce2-52567e06e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont execute this\n",
    "columns_to_drop = ['How many Organization that you have worked before joining Piramal Finance ?',\n",
    "                  'CandidateID', 'Designation', 'DOJ', 'Location Code']\n",
    "train = train.drop(columns=columns_to_drop)\n",
    "test = test.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2d801db-1731-44f7-9d78-dc7b2405739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resume_data.pkl\", \"rb\") as file:\n",
    "    resume_text_new = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b860e52-3230-49f2-82bb-79f5633c2f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_txt = pd.DataFrame(resume_text_new, columns=['resume_txt'])\n",
    "df = pd.concat([train, resume_txt], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea92410-b67d-49d4-92a8-48aae1171364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional\n",
    "with open(\"resume_data_test.pkl\", \"rb\") as file:\n",
    "    resume_text_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da78533-db16-4ecc-a006-41656c176d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resume_data_test_new1.pkl\", \"rb\") as file:\n",
    "    resume_text_test1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd598db9-33a5-4787-bc17-d4ff672b7cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resume_data_test_new2.pkl\", \"rb\") as file:\n",
    "    resume_text_test2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba1b0b0b-9265-4ca6-98a0-38541ba7789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#resume_text_test = resume_text_test1 + resume_text_test2\n",
    "resume_test = pd.DataFrame(resume_text_test, columns = ['resume_txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06f08fa2-a6df-45fa-b6ba-a9f982174a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test, resume_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "382b9da3-0ee6-4694-b5d1-6e2f1b0dbc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('train1.csv', index=False)\n",
    "test.to_csv('test1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6b4eb91-e98c-4520-b1e4-b886fe3d397a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CandidateID', 'Designation',\n",
       "       'Total no of years Experience [before joining Piramal]',\n",
       "       'Previous Industry worked with [before joining Piramal]',\n",
       "       'Name of your Previous Organization / Company',\n",
       "       'How many Organization that you have worked before joining Piramal Finance ?',\n",
       "       'Average Incentive [per month] earned in your pervious company ?',\n",
       "       'How did you come to know about the role at Piramal Finance ?',\n",
       "       'Which Products you are selling in your pervious role ?',\n",
       "       'What was the average ticket size handled at your end in previous role ?',\n",
       "       'How many members are there in your family ?',\n",
       "       'How many are earning family members ? [Other then yourself]2',\n",
       "       'How many members are dependent on you ?', 'Department', 'DOJ',\n",
       "       'Location Code', 'Performance', 'education', 'resume_txt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.core.dataset import TabularDataset\n",
    "train_data = TabularDataset('train1.csv')\n",
    "train_data.head(30)\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d093c68f-240e-4616-9ea6-660689d9f53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240410_185109\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240410_185109\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          16\n",
      "Memory Avail:       5.85 GB / 15.63 GB (37.4%)\n",
      "Disk Space Avail:   112.68 GB / 365.58 GB (30.8%)\n",
      "===================================================\n",
      "Train Data Rows:    745\n",
      "Train Data Columns: 18\n",
      "Label Column:       Performance\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5981.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.41 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Name of your Previous Organization / Company', 'Which Products you are selling in your pervious role ?', 'What was the average ticket size handled at your end in previous role ?', 'education', 'resume_txt']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 1555\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['Designation']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['CandidateID']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['CandidateID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 2 | ['Total no of years Experience [before joining Piramal]', 'How many are earning family members ? [Other then yourself]2']\n",
      "\t\t('int', [])                        : 2 | ['How many members are dependent on you ?', 'Location Code']\n",
      "\t\t('object', [])                     : 6 | ['Previous Industry worked with [before joining Piramal]', 'How many Organization that you have worked before joining Piramal Finance ?', 'Average Incentive [per month] earned in your pervious company ?', 'How did you come to know about the role at Piramal Finance ?', 'How many members are there in your family ?', ...]\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['DOJ']\n",
      "\t\t('object', ['text'])               : 5 | ['Name of your Previous Organization / Company', 'Which Products you are selling in your pervious role ?', 'What was the average ticket size handled at your end in previous role ?', 'education', 'resume_txt']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    6 | ['Previous Industry worked with [before joining Piramal]', 'How many Organization that you have worked before joining Piramal Finance ?', 'Average Incentive [per month] earned in your pervious company ?', 'How did you come to know about the role at Piramal Finance ?', 'How many members are there in your family ?', ...]\n",
      "\t\t('category', ['text_as_category'])  :    4 | ['Name of your Previous Organization / Company', 'Which Products you are selling in your pervious role ?', 'What was the average ticket size handled at your end in previous role ?', 'education']\n",
      "\t\t('float', [])                       :    2 | ['Total no of years Experience [before joining Piramal]', 'How many are earning family members ? [Other then yourself]2']\n",
      "\t\t('int', [])                         :    2 | ['How many members are dependent on you ?', 'Location Code']\n",
      "\t\t('int', ['binned', 'text_special']) :   57 | ['Name of your Previous Organization / Company.char_count', 'Name of your Previous Organization / Company.word_count', 'Name of your Previous Organization / Company.capital_ratio', 'Name of your Previous Organization / Company.lower_ratio', 'Name of your Previous Organization / Company.digit_ratio', ...]\n",
      "\t\t('int', ['datetime_as_int'])        :    5 | ['DOJ', 'DOJ.year', 'DOJ.month', 'DOJ.day', 'DOJ.dayofweek']\n",
      "\t\t('int', ['text_ngram'])             : 1475 | ['__nlp__.00', '__nlp__.01', '__nlp__.02', '__nlp__.03', '__nlp__.04', ...]\n",
      "\t19.0s = Fit runtime\n",
      "\t16 features in original data used to generate 1551 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.20 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 19.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 596, Val Rows: 149\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.6711\t = Validation score   (accuracy)\n",
      "\t0.3s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.6711\t = Validation score   (accuracy)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "C:\\Users\\91939\\anaconda3\\lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 6.0.1. Please consider upgrading.\n",
      "  warnings.warn(\n",
      "\t0.6577\t = Validation score   (accuracy)\n",
      "\t2.65s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.6644\t = Validation score   (accuracy)\n",
      "\t1.32s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.604\t = Validation score   (accuracy)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.5906\t = Validation score   (accuracy)\n",
      "\t1.69s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.6913\t = Validation score   (accuracy)\n",
      "\t26.53s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.5973\t = Validation score   (accuracy)\n",
      "\t1.78s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6107\t = Validation score   (accuracy)\n",
      "\t2.07s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "C:\\Users\\91939\\anaconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "C:\\Users\\91939\\anaconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "No improvement since epoch 7: early stopping\n",
      "C:\\Users\\91939\\anaconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\t0.6107\t = Validation score   (accuracy)\n",
      "\t4.32s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.651\t = Validation score   (accuracy)\n",
      "\t1.44s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6376\t = Validation score   (accuracy)\n",
      "\t5.82s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.651\t = Validation score   (accuracy)\n",
      "\t3.13s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'KNeighborsUnif': 0.4, 'CatBoost': 0.2, 'ExtraTreesGini': 0.2, 'NeuralNetTorch': 0.2}\n",
      "\t0.7383\t = Validation score   (accuracy)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 75.57s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240410_185109\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor \n",
    "predictor = TabularPredictor(label='Performance').fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04194fa3-4ba0-45c9-b426-6d827472bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: test1.csv | Columns = 18 / 18 | Rows = 187 -> 187\n",
      "WARNING: Int features without null values at train time contain null values at inference time! Imputing nulls to 0. To avoid this, pass the features as floats during fit!\n",
      "WARNING: Int features with nulls: ['Location Code']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Performance, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset('test1.csv')\n",
    "label = 'CandidateID'\n",
    "y_pred = predictor.predict((test_data))\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfc407e3-71ae-4d84-bd7a-d4b74f4bd805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CandidateID</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMP0521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMP0613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMP0136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMP0351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMP0049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>EMP0401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>EMP0408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>EMP0248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>EMP0148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>EMP0422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CandidateID  Performance\n",
       "0       EMP0521            1\n",
       "1       EMP0613            1\n",
       "2       EMP0136            0\n",
       "3       EMP0351            0\n",
       "4       EMP0049            0\n",
       "..          ...          ...\n",
       "182     EMP0401            1\n",
       "183     EMP0408            0\n",
       "184     EMP0248            0\n",
       "185     EMP0148            0\n",
       "186     EMP0422            0\n",
       "\n",
       "[187 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub=pd.DataFrame()\n",
    "sub['CandidateID'],sub['Performance']=test_data['CandidateID'],y_pred\n",
    "sub.to_csv('submission_3.csv', index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aa67ba-81f7-48b9-aa99-f90aa1be87ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
