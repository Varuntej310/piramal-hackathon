{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "751b6b06-8e84-4041-b793-da47552a8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import string\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e094bf3-75ca-4781-98c3-94de31bf9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_dist.csv')\n",
    "test = pd.read_csv('test_dist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a0c17e6-ae82-4622-83be-20f5ecd9ac9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CandidateID', 'Designation',\n",
       "       'Total no of years Experience [before joining Piramal]',\n",
       "       'Previous Industry worked with [before joining Piramal]',\n",
       "       'Name of your Previous Organization / Company',\n",
       "       'How many Organization that you have worked before joining Piramal Finance ?',\n",
       "       'Average Incentive [per month] earned in your pervious company ?',\n",
       "       'How did you come to know about the role at Piramal Finance ?',\n",
       "       'Which Products you are selling in your pervious role ?',\n",
       "       'What was the average ticket size handled at your end in previous role ?',\n",
       "       'How many members are there in your family ?',\n",
       "       'How many are earning family members ? [Other then yourself]2',\n",
       "       'How many members are dependent on you ?', 'Department', 'DOJ',\n",
       "       'Location Code', 'Residential Pincode', 'Branch Pincode', 'Performance',\n",
       "       'education', 'train_vector', 'branch_lat', 'branch_lon',\n",
       "       'residential_lat', 'residential_lon', 'distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f491f93-3016-441c-81f1-016e2d45100a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['branch_lat','branch_lon', 'residential_lat', 'residential_lon'], axis=1)\n",
    "test = test.drop(['branch_lat','branch_lon', 'residential_lat', 'residential_lon'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f51e9523-429d-447d-8968-bcbfecc08aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resume_data.pkl\", \"rb\") as file:\n",
    "    resume_text = pickle.load(file)\n",
    "    \n",
    "with open(\"resume_data_test.pkl\", \"rb\") as file:\n",
    "    resume_text_test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a67f27aa-2fc0-43b0-b6b8-9b7a06866dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(text):\n",
    "\n",
    "    final_string = \"\"\n",
    "\n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove punctionation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "\n",
    "    # Remove stop words and usless words\n",
    "    text = text.split()\n",
    "    useless_words = nltk.corpus.stopwords.words(\"english\")\n",
    "    text_filtered = [word for word in text if not word in useless_words]\n",
    "\n",
    "    # Stem the text with NLTK PorterStemmer\n",
    "    stemmer = PorterStemmer() \n",
    "    text_stemmed = [stemmer.stem(y) for y in text_filtered]\n",
    "\n",
    "    # Join the words back into a string\n",
    "    final_string = ' '.join(text_stemmed)\n",
    "\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80c7e4b7-96e5-44bc-9ea8-9b2a7c9ef90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91939\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eee30c0f-cdc5-4e32-a1e2-fc571f19697a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86e585a1-b9ad-48a0-a93f-05c5c903bfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 745/745 [00:25<00:00, 29.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 187/187 [00:06<00:00, 30.49it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_tagged = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(resume_text)]\n",
    "test_tagged = [TaggedDocument(doc.split(), [i]) for i, doc in enumerate(resume_text_test)]\n",
    "\n",
    "# Train the Doc2Vec model\n",
    "model = Doc2Vec(vector_size=700, min_count=2, epochs=40)\n",
    "model.build_vocab(train_tagged)\n",
    "model.train(train_tagged, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# Get the document vectors\n",
    "train_vectors = [model.infer_vector(doc.words) for doc in tqdm(train_tagged)]\n",
    "test_vectors = [model.infer_vector(doc.words) for doc in tqdm(test_tagged)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8992ad5-6b56-4746-9260-ae27d1450924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['vectors'] = train_vectors\n",
    "# test['vectors'] = test_vectors\n",
    "train = train.drop(['train_vector', 'CandidateID', 'Designation', 'Location Code', 'Residential Pincode', 'Branch Pincode'], axis=1)\n",
    "test = test.drop(['train_vector', 'CandidateID', 'Designation', 'Location Code', 'Residential Pincode', 'Branch Pincode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "976b84f0-98f0-493a-9970-ce1708792eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['resume'] = pd.DataFrame(resume_text, columns=['resume'])\n",
    "test['resume'] = pd.DataFrame(resume_text_test, columns=['resume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "699d392c-fcb5-45c1-9d7c-d36fcf13b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train1.csv', index=False)\n",
    "test.to_csv('test1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d12c3185-485b-4185-a284-ea2ac52fe38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: train.csv | Columns = 21 / 21 | Rows = 745 -> 745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['CandidateID', 'Designation', 'Have you Completed your Graduation ?',\n",
       "       'Highest Educational Qualification',\n",
       "       'Total no of years Experience [before joining Piramal]',\n",
       "       'Previous Industry worked with [before joining Piramal]',\n",
       "       'Name of your Previous Organization / Company',\n",
       "       'How many Organization that you have worked before joining Piramal Finance ?',\n",
       "       'Average Incentive [per month] earned in your pervious company ?',\n",
       "       'How did you come to know about the role at Piramal Finance ?',\n",
       "       'Which Products you are selling in your pervious role ?',\n",
       "       'What was the average ticket size handled at your end in previous role ?',\n",
       "       'How many members are there in your family ?',\n",
       "       'How many are earning family members ? [Other then yourself]2',\n",
       "       'How many members are dependent on you ?', 'Department', 'DOJ',\n",
       "       'Location Code', 'Residential Pincode', 'Branch Pincode',\n",
       "       'Performance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.core.dataset import TabularDataset\n",
    "train_data = TabularDataset('train.csv')\n",
    "train_data.head(30)\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "941ce753-a172-4f03-9e24-3da299330d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240411_133137\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240411_133137\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.14\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          16\n",
      "Memory Avail:       3.98 GB / 15.63 GB (25.5%)\n",
      "Disk Space Avail:   108.88 GB / 365.58 GB (29.8%)\n",
      "===================================================\n",
      "Train Data Rows:    745\n",
      "Train Data Columns: 20\n",
      "Label Column:       Performance\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4078.71 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.70 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Name of your Previous Organization / Company', 'Which Products you are selling in your pervious role ?', 'What was the average ticket size handled at your end in previous role ?']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 89\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 89 to 76 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['Designation']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 1): ['CandidateID']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['CandidateID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      : 3 | ['Total no of years Experience [before joining Piramal]', 'How many are earning family members ? [Other then yourself]2', 'Branch Pincode']\n",
      "\t\t('int', [])                        : 3 | ['How many members are dependent on you ?', 'Location Code', 'Residential Pincode']\n",
      "\t\t('object', [])                     : 8 | ['Have you Completed your Graduation ?', 'Highest Educational Qualification', 'Previous Industry worked with [before joining Piramal]', 'How many Organization that you have worked before joining Piramal Finance ?', 'Average Incentive [per month] earned in your pervious company ?', ...]\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['DOJ']\n",
      "\t\t('object', ['text'])               : 3 | ['Name of your Previous Organization / Company', 'Which Products you are selling in your pervious role ?', 'What was the average ticket size handled at your end in previous role ?']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  8 | ['Have you Completed your Graduation ?', 'Highest Educational Qualification', 'Previous Industry worked with [before joining Piramal]', 'How many Organization that you have worked before joining Piramal Finance ?', 'Average Incentive [per month] earned in your pervious company ?', ...]\n",
      "\t\t('category', ['text_as_category'])  :  3 | ['Name of your Previous Organization / Company', 'Which Products you are selling in your pervious role ?', 'What was the average ticket size handled at your end in previous role ?']\n",
      "\t\t('float', [])                       :  3 | ['Total no of years Experience [before joining Piramal]', 'How many are earning family members ? [Other then yourself]2', 'Branch Pincode']\n",
      "\t\t('int', [])                         :  3 | ['How many members are dependent on you ?', 'Location Code', 'Residential Pincode']\n",
      "\t\t('int', ['binned', 'text_special']) : 25 | ['Name of your Previous Organization / Company.char_count', 'Name of your Previous Organization / Company.word_count', 'Name of your Previous Organization / Company.capital_ratio', 'Name of your Previous Organization / Company.lower_ratio', 'Name of your Previous Organization / Company.digit_ratio', ...]\n",
      "\t\t('int', ['datetime_as_int'])        :  5 | ['DOJ', 'DOJ.year', 'DOJ.month', 'DOJ.day', 'DOJ.dayofweek']\n",
      "\t\t('int', ['text_ngram'])             : 49 | ['__nlp__.15l', '__nlp__.15l and', '__nlp__.2l', '__nlp__.2l inr', '__nlp__.50k', ...]\n",
      "\t2.0s = Fit runtime\n",
      "\t18 features in original data used to generate 96 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.16 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 596, Val Rows: 149\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.5586\t = Validation score   (f1)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.5664\t = Validation score   (f1)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.6261\t = Validation score   (f1)\n",
      "\t1.73s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.595\t = Validation score   (f1)\n",
      "\t1.7s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.5234\t = Validation score   (f1)\n",
      "\t1.21s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.566\t = Validation score   (f1)\n",
      "\t1.21s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.5739\t = Validation score   (f1)\n",
      "\t28.73s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.5\t = Validation score   (f1)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.4571\t = Validation score   (f1)\n",
      "\t1.02s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "C:\\Users\\91939\\anaconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "C:\\Users\\91939\\anaconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "C:\\Users\\91939\\anaconda3\\lib\\site-packages\\autogluon\\tabular\\models\\fastainn\\tabular_nn_fastai.py:200: FutureWarning: The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "  df = df.fillna(column_fills, inplace=False, downcast=False)\n",
      "\t0.592\t = Validation score   (f1)\n",
      "\t2.74s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.6667\t = Validation score   (f1)\n",
      "\t1.64s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.5714\t = Validation score   (f1)\n",
      "\t17.74s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.5983\t = Validation score   (f1)\n",
      "\t2.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'KNeighborsUnif': 0.333, 'XGBoost': 0.333, 'RandomForestGini': 0.19, 'RandomForestEntr': 0.095, 'LightGBMXT': 0.048}\n",
      "\t0.7304\t = Validation score   (f1)\n",
      "\t3.98s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 68.14s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240411_133137\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor \n",
    "time_limit = 90\n",
    "predictor = TabularPredictor(label='Performance',eval_metric='f1').fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ac3650a-d2c2-4b5d-b3fb-003cca88b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pd.read_csv('test.csv',  encoding='ISO-8859-1')\n",
    "test2.to_csv('test2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0306c2a-8b51-4845-bf74-fe72333a630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: test2.csv | Columns = 20 / 20 | Rows = 187 -> 187\n",
      "WARNING: Int features without null values at train time contain null values at inference time! Imputing nulls to 0. To avoid this, pass the features as floats during fit!\n",
      "WARNING: Int features with nulls: ['Location Code']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Performance, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset('test2.csv')\n",
    "label = 'CandidateID'\n",
    "y_pred = predictor.predict((test_data))\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbdee7ee-d233-4df3-ab4c-085189a2201b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CandidateID</th>\n",
       "      <th>Performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EMP0521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMP0613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMP0136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMP0351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMP0049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>EMP0401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>EMP0408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>EMP0248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>EMP0148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>EMP0422</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CandidateID  Performance\n",
       "0       EMP0521            1\n",
       "1       EMP0613            1\n",
       "2       EMP0136            0\n",
       "3       EMP0351            0\n",
       "4       EMP0049            0\n",
       "..          ...          ...\n",
       "182     EMP0401            1\n",
       "183     EMP0408            0\n",
       "184     EMP0248            0\n",
       "185     EMP0148            0\n",
       "186     EMP0422            0\n",
       "\n",
       "[187 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub=pd.DataFrame()\n",
    "sub['CandidateID'],sub['Performance']=test_data['CandidateID'],y_pred\n",
    "sub.to_csv('submission_7.csv', index=False)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845584da-6d9e-4621-a997-d6fd7781bfb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
